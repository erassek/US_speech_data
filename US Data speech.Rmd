---
title: "US Speech report"
author: "Emmanuelle RASSEK"
date: "February 2019"
output: 
  word_document: default
  html_document: default
  pdf_document: default
---
```

##Report##
##US presidential speech analysis##

```{r setup, include=FALSE}

US.Presidential.Data <- read.csv("C:/Users/manu/Downloads/US Presidential Data.csv")
data_US <- US.Presidential.Data

# load library
library(caret)
library(e1071)
library(dplyr)
library(tidyverse)


# Transforming the dependent variable to a factor
data_US$Win.Loss = as.factor(data_US$Win.Loss)


# Exploratory data analysis
ggplot(gather(data_US[,2:ncol(data_US)]), aes(value)) + 
  geom_histogram(bins = 5, fill = "blue", alpha = 0.6) + 
  facet_wrap(~key, scales = 'free_x')

#Partitioning the data into training and validation data
set.seed(101)
index = createDataPartition(data_US$Win.Loss, p = 0.7, list = F )
train_set = data_US[index,]
validation_set = data_US[-index,]



# Setting levels for both training and validation data
levels(train_set$Win.Loss) <- make.names(levels(factor(train_set$Win.Loss)))
levels(validation_set$Win.Loss) <- make.names(levels(factor(validation_set$Win.Loss)))


```

###1. Executive summary###

K Nearest Neighbors is non parametric supervised machine learning algorithm used for classification and regression. It calculates similarity amongst observations based on a distance function (usually Euclidean) and preferred when data is continuous. 

For this project, we will use the "Presidential Debates" dataset (Data_US) composed of 14 variables. The objective is to create a KNN model to predict if a candidate will win or lose a speech.

In order to do so, we will divide the dataset into two subsets:

- a training subset to train our algorithm, called "train_set" (70%)
- a validation subset to predict the movie ratings, called "validation_set" (30%)

In the first part of the report, we will use techniques such as data exploration and visualization to have an overview of the dataset. Then, we will create a KNN model with the best possible accuracy (ROC). Finally, we will explain the results and conclude. All the analysis will be made through R studio and the following packages: caret, e1071,dplyr and tidyverse.


###2. Analysis: data description, preparation, exploration and visualization###

#### 2.A. Data description ####


In this section we will take a first look at our datasetsand check if data cleaning is necessary. 

Please find below the structure of the datasets: 

- data_US (complete dataset): 1524 observations of  14 variables

- train_set: 1068 observations of  14 variables

- validation_set: 456 observations of  14 variables

```{r}
dim(data_US)
dim(train_set)
dim(validation_set)

```

It seems that there is no missing data and no data cleaning necessary. 
However we need to set levels for both training and validation data.

```{r}
# Setting levels for both training and validation data
levels(train_set$Win.Loss) <- make.names(levels(factor(train_set$Win.Loss)))
levels(validation_set$Win.Loss) <- make.names(levels(factor(validation_set$Win.Loss)))

```

Please find below the 14 variables: "Win.Loss", "Optimism", "Pessimism", "PastUsed", "FutureUsed", "PresentUsed",  "OwnPartyCount", "OppPartyCount", "NumericContent", "Extra", "Emoti", "Agree", "Consc" and "Openn".  

In our analysis "Win.Loss" is the dependant variable whereas the 13 others are the independant variables.

#### 2.B. Data exploration ####

Let's analyse the structure of the 14 variables:

```{r}
summary(data_US$Win.Loss)
summary(data_US$Optimism)
summary(data_US$Pessimism)
summary(data_US$PastUsed)
summary(data_US$Futureused)
summary(data_US$PresentUsed)
summary(data_US$OwnPartyCount)
summary(data_US$OppPartyCount)
summary(data_US$NumericContent)
summary(data_US$Extra)
summary(data_US$Emoti)
summary(data_US$Agree)
summary(data_US$Consc)
summary(data_US$Win.Openn)
```


####  2.C. Data visualization ####

**Please find below the graphics of the 13 independant variables**
```{r setup2, include=FALSE}

ggplot(gather(data_US[,2:ncol(data_US)]), aes(value)) + 
  geom_histogram(bins = 5, fill = "blue", alpha = 0.6) + 
  facet_wrap(~key, scales = 'free_x')
  
```

Thanks to the preparation and exploration of the dataset, we are now ready to create our machine learning model. 

####  2.D. Modelling approach####

The objective is to define a method that will allow us to train several algorithms in order to identify the best one. 

We will proceed in five steps:

- Setting up train controls

- training of the KNN model (on train_set)

- predictions (on the validation_set)

- analysis of the ROC and AUC. 

- conclusion


### 3. Data analysis and results ###

**Data partition**

In order to reach our goal, we we divided the Data_US dataset into two subsets:

- the training subset to train our algorithm, called "train_set" (70% of MovieLens data)
- the validation subset to predict the result of the speech, called"validation_set" (30% of MovieLens data)

We are now ready to create our predictive model. 


**Setting up train controls**

Let's set up the train controls and the KNN model. 

```{r}
repeats = 3
numbers = 10
tunel = 10

set.seed(1234)
x <- trainControl(method = "repeatedcv",
                 number = numbers,
                 repeats = repeats,
                 classProbs = TRUE,
                 summaryFunction = twoClassSummary)
                 

```

**Training of the model**

We are now ready to train our KNN model:

```{r}

model_knn <- train(Win.Loss~., data= train_set, method="knn", 
                preProcess=c("center","scale"),
                trControl=x,metric="ROC",
                tuneLength= tunel)
                
# Summary of model
model_knn
plot(model_knn)

```

**Predictions**


```{r}
# Validation
valid_pred <- predict(model_knn,validation_set, type = "prob")
```

**Results analysis**

```{r}
#Storing Model Performance Scores
library(ROCR)
pred_val <-prediction(valid_pred[,2],validation_set$Win.Loss)

# Calculating Area under Curve (AUC)
perf_val <- performance(pred_val,"auc")
perf_val

# Plot AUC
perf_val <- performance(pred_val, "tpr", "fpr")
plot(perf_val, col = "green", lwd = 1.5)
```

### 4. Conclusion ###


```{r}

```
The Area under curve (AUC) on validation dataset is .



